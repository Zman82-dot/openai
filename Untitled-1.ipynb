{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = OpenAI.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def collect_messages(response,model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "        model=model\n",
    "        prompt = prompt\n",
    "        context = [{'role': 'user', 'content': prompt}]\n",
    "        response = get_completion_from_messages(context)\n",
    "        return ({'response': response})\n",
    "    \n",
    "def generate_audio_content(response):\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Generate speech content based on the prompt\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=response\n",
    ")\n",
    "\n",
    "    # Get the parent directory of the script\n",
    "    notebook_dir = Path.cwd()\n",
    "    speech_file_path = notebook_dir / \"speech.mp3\"\n",
    "\n",
    "    # Extract the content from the response\n",
    "    audio_content = response.content\n",
    "\n",
    "    # Write the audio content to the file\n",
    "    with open(speech_file_path, \"wb\") as f:\n",
    "        f.write(audio_content)\n",
    "\n",
    "    # Return the path to the saved MP3 file\n",
    "    return speech_file_path\n",
    "\n",
    "# Prompt for generating speech\n",
    "prompt = input(\"Enter your prompt: \")\n",
    "response = input\n",
    "# Call the function to generate and save audio content\n",
    "mp3_file_path = generate_audio_content(prompt)\n",
    "\n",
    "# Function to play MP3 file\n",
    "def play_mp3(file_path):\n",
    "    pygame.init()\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(file_path)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Keep the script running until the music finishes playing  \n",
    "     \n",
    "    clock = pygame.time.Clock()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        clock.tick(30)\n",
    "\n",
    "    # Clean up\n",
    "    pygame.mixer.quit()\n",
    "    pygame.quit()\n",
    "\n",
    "# Call the function to play the MP3 file\n",
    "play_mp3(mp3_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"/home/dorianrcoleman/openai-env/output.mp3\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-vision-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Whatâ€™s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://scontent-iad3-2.xx.fbcdn.net/v/t1.18169-9/1609718_858530737491864_7426936010246521272_n.jpg?_nc_cat=105&ccb=1-7&_nc_sid=5f2048&_nc_ohc=Xqj6rcQzvTUAX-ICOLp&_nc_ht=scontent-iad3-2.xx&oh=00_AfDscZEQP1Oee0EAXtulfnKMJYYbxTMf20j8JBtNmUlrfg&oe=66283F9E\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def generate_audio(prompt):\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Generate audio content based on the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        text=prompt\n",
    "    )\n",
    "\n",
    "    return response[\"audio\"]\n",
    "\n",
    "def main():\n",
    "    # User prompt\n",
    "    prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "    # Generate audio from OpenAI\n",
    "    audio_content = generate_audio(prompt)\n",
    "\n",
    "    # Save the audio to a file or play it directly\n",
    "\n",
    "    # For demonstration, let's save it to a file\n",
    "    with open(\"response_audio.mp3\", \"wb\") as f:\n",
    "        f.write(audio_content)\n",
    "\n",
    "    print(\"Audio generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"hello\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Hello! How can I assist you today?\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "result = client.chat.completions.create\n",
    "print(result[0].message.content)\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/audio/speech\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"tts-1-1106\",\n",
    "        \"input\": result.message.content,\n",
    "        \"voice\": \"onyx\",\n",
    "    },\n",
    ")\n",
    "\n",
    "audio = b\"\"\n",
    "for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "    audio += chunk\n",
    "Audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Image, Audio\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Input prompt for chat completion\n",
    "input_prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "# Chat completion with GPT-4 vision model\n",
    "params = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": input_prompt}],\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message[\"content\"])  # Access the content directly\n",
    "\n",
    "# Chat completion with GPT-3.5 turbo model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"hello?\"},\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message[\"content\"])  # Ensure this line is correct\n",
    "\n",
    "# Speech synthesis with TTS-1-1106 model\n",
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/audio/speech\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"tts-1-1106\",\n",
    "        \"input\": result.choices[0].message, # Use result.choices[0].content\n",
    "        \"voice\": \"onyx\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Extract audio content from response\n",
    "audio = b\"\"\n",
    "for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "    audio += chunk\n",
    "\n",
    "# Display the audio\n",
    "Audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Audio\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Input prompt for chat completion\n",
    "input_prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "# Chat completion with GPT-4 vision model\n",
    "params = {\n",
    "    \"model\": \"gpt-3.5turbo0125\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": input_prompt}],\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message)  # Access the content directly\n",
    "\n",
    "# Chat completion with GPT-3.5 turbo model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"hello?\"},\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.json)  # Ensure this line is correct\n",
    "\n",
    "prompt = input(\"Enter your prompt: \")\n",
    "response = input\n",
    "# Call the function to generate and save audio content\n",
    "mp3_file_path = generate_audio_content(prompt)\n",
    "\n",
    "# Function to play MP3 file\n",
    "def play_mp3(file_path):\n",
    "    pygame.init()\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(file_path)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Keep the script running until the music finishes playing  \n",
    "     \n",
    "    clock = pygame.time.Clock()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        clock.tick(30)\n",
    "\n",
    "    # Clean up\n",
    "    pygame.mixer.quit()\n",
    "    pygame.quit()\n",
    "\n",
    "# Call the function to play the MP3 file\n",
    "play_mp3(mp3_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Audio\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Input prompt for chat completion\n",
    "input_prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "# Chat completion with GPT-4 vision model\n",
    "params = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": input_prompt}],\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message)  # Access the content directly\n",
    "\n",
    "# Chat completion with GPT-3.5 turbo model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"hello?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello! How can I assist you today?\"},  # Add assistant message\n",
    "        {\"role\": \"json\", \"content\": \"\"}  # Ensure 'json' is included in the message\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message[\"content\"])  # Print only the content of the message\n",
    "\n",
    "# Speech synthesis with TTS-1-1106 model\n",
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/audio/speech\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"tts-1-1106\",\n",
    "        \"content\": response.choices[0].message.model_json_schema,  # Use result.choices[0].message[\"content\"]\n",
    "        \"voice\": \"onyx\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Extract audio content from response\n",
    "audio = b\"\"\n",
    "for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "    audio += chunk\n",
    "\n",
    "# Display the audio\n",
    "Audio(audio).autoplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletionMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 60\u001b[0m\n\u001b[1;32m     54\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-0125\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_prompt}],\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     58\u001b[0m }\n\u001b[1;32m     59\u001b[0m result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Access the content directly\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Chat completion with GPT-3.5 turbo model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     64\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-0125\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     ]\n\u001b[1;32m     70\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletionMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "import os\n",
    "import pygame\n",
    "from pathlib import Path\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = OpenAI.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def collect_messages(response, model=\"gpt-3.5-turbo\"):\n",
    "    model = model\n",
    "    prompt = prompt\n",
    "    context = [{'role': 'user', 'content': prompt}]\n",
    "    response = get_completion_from_messages(context)\n",
    "    return {'response': response}\n",
    "\n",
    "def generate_audio_content(response):\n",
    "    client = OpenAI()\n",
    "    OPENAI_API_KEY = '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'\n",
    "    \n",
    "    # Generate speech content based on the prompt\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=response\n",
    "    )\n",
    "\n",
    "    # Get the parent directory of the script\n",
    "    notebook_dir = Path.cwd()\n",
    "    speech_file_path = notebook_dir / \"speech.mp3\"\n",
    "\n",
    "    # Extract the content from the response\n",
    "    audio_content = response.content\n",
    "\n",
    "    # Write the audio content to the file\n",
    "    with open(speech_file_path, \"wb\") as f:\n",
    "        f.write(audio_content)\n",
    "\n",
    "    # Return the path to the saved MP3 file\n",
    "    return speech_file_path\n",
    "\n",
    "# Input prompt for chat completion\n",
    "input_prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Chat completion with GPT-4 vision model\n",
    "params = {\n",
    "    \"model\": \"gpt-3.5-turbo-0125\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": input_prompt}],\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message[\"content\"])  # Access the content directly\n",
    "\n",
    "# Chat completion with GPT-3.5 turbo model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"hello?\"},\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.json)  # Ensure this line is correct\n",
    "\n",
    "# Call the function to generate and save audio content\n",
    "mp3_file_path = generate_audio_content(response.choices[0].message[\"content\"])\n",
    "\n",
    "# Function to play MP3 file\n",
    "def play_mp3(file_path):\n",
    "    pygame.init()\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(file_path)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Keep the script running until the music finishes playing\n",
    "    clock = pygame.time.Clock()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        clock.tick(30)\n",
    "\n",
    "    # Clean up\n",
    "    pygame.mixer.quit()\n",
    "    pygame.quit()\n",
    "\n",
    "# Call the function to play the MP3 file\n",
    "play_mp3(mp3_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('openai-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f0e5833e0cbbc46e0aa4e4a4716c735b45baa636c0b65e76e453065ee69dc30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
